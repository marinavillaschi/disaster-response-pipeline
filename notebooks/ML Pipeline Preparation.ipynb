{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pipelinehelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Qesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Qesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Qesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "# from pipelinehelper import PipelineHelper\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///disastermanagement.db')\n",
    "df = pd.read_sql_table('labeledmessages', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into feature and target variables\n",
    "X = df['message']\n",
    "Y = df.drop(columns = ['id', 'message', 'original', 'genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multilabel-indicator'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.multiclass import type_of_target\n",
    "type_of_target(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Method to process the text data into lemmatized tokens\n",
    "\n",
    "    Args:\n",
    "        text: text data to be processed\n",
    "\n",
    "    Returns:\n",
    "        list: clean_tokes list with tokens extracted from the processed text data \n",
    "    \"\"\"\n",
    "    # normalize case and remove leading/trailing white space and punctuation\n",
    "    text = re.sub(\"\\W\",\" \", text.lower().strip())\n",
    "    \n",
    "    # tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # initiate stopword\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    \n",
    "    # initiate lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # iterate through each token to\n",
    "    # lemmatize and remove stopwords  \n",
    "    clean_tokens = []\n",
    "    \n",
    "    for tok in tokens:\n",
    "        if tok not in stop_words:\n",
    "\n",
    "            clean_tok = lemmatizer.lemmatize(tok)\n",
    "            clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Giving some models a shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(model):\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(model))\n",
    "    ])\n",
    "      \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Train and evaluate the pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the models to train\n",
    "lr_pipeline = model_pipeline(LogisticRegression(random_state = random_state))\n",
    "svc_pipeline = model_pipeline(LinearSVC(random_state = random_state))\n",
    "nb_pipeline = model_pipeline(MultinomialNB())\n",
    "knc_pipeline = model_pipeline(KNeighborsClassifier())\n",
    "tree_pipeline = model_pipeline(DecisionTreeClassifier(random_state = random_state))\n",
    "rf_pipeline = model_pipeline(RandomForestClassifier(random_state = random_state))\n",
    "\n",
    "models_part1 = [lr_pipeline, svc_pipeline, nb_pipeline]\n",
    "models_part2 = [knc_pipeline, tree_pipeline, rf_pipeline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# train and validate models part 1\n",
    "df_result1 = pd.DataFrame()\n",
    "\n",
    "for model in models_part1:\n",
    "    scores = cross_val_score(model, X_train, y_train,\n",
    "                             scoring = 'f1_samples', cv = 5)\n",
    "    f1score = scores\n",
    "    mean = f1score.mean()\n",
    "    std = f1score.std()\n",
    "    df_result1 = df_result1.append({\n",
    "                                  'MODEL': str(model.named_steps['clf'].estimator).split('(')[0], 'SCORES': f1score, \n",
    "                                  'MEAN_SCORES': mean, 'STD_SCORES': std \n",
    "                                  }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEAN_SCORES</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>SCORES</th>\n",
       "      <th>STD_SCORES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.514625</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[0.513047708223, 0.50890900552, 0.517944604815...</td>\n",
       "      <td>0.003467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.501321</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>[0.497336722115, 0.498439652359, 0.49720207704...</td>\n",
       "      <td>0.005166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470794</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>[0.462157473731, 0.467792671585, 0.48257941258...</td>\n",
       "      <td>0.007669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MEAN_SCORES               MODEL  \\\n",
       "0     0.514625  LogisticRegression   \n",
       "1     0.501321           LinearSVC   \n",
       "2     0.470794       MultinomialNB   \n",
       "\n",
       "                                              SCORES  STD_SCORES  \n",
       "0  [0.513047708223, 0.50890900552, 0.517944604815...    0.003467  \n",
       "1  [0.497336722115, 0.498439652359, 0.49720207704...    0.005166  \n",
       "2  [0.462157473731, 0.467792671585, 0.48257941258...    0.007669  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# train and validate models part 2\n",
    "df_result2 = pd.DataFrame()\n",
    "\n",
    "for model in models_part2:\n",
    "    scores = cross_val_score(model, X_train, y_train,\n",
    "                             scoring = 'f1_samples', cv = 5, n_jobs=-1)\n",
    "    f1score = scores\n",
    "    mean = f1score.mean()\n",
    "    std = f1score.std()\n",
    "    df_result2 = df_result2.append({\n",
    "                                  'MODEL': str(model.named_steps['clf'].estimator).split('(')[0], 'SCORES': f1score, \n",
    "                                  'MEAN_SCORES': mean, 'STD_SCORES': std \n",
    "                                  }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEAN_SCORES</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>SCORES</th>\n",
       "      <th>STD_SCORES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.440248</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>[0.437373002227, 0.433996509004, 0.44772590159...</td>\n",
       "      <td>0.005180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.461471</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>[0.464829925804, 0.454389031791, 0.46416511469...</td>\n",
       "      <td>0.004158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.476431</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[0.471439794621, 0.471389868978, 0.48552065950...</td>\n",
       "      <td>0.005240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MEAN_SCORES                   MODEL  \\\n",
       "0     0.440248    KNeighborsClassifier   \n",
       "1     0.461471  DecisionTreeClassifier   \n",
       "2     0.476431  RandomForestClassifier   \n",
       "\n",
       "                                              SCORES  STD_SCORES  \n",
       "0  [0.437373002227, 0.433996509004, 0.44772590159...    0.005180  \n",
       "1  [0.464829925804, 0.454389031791, 0.46416511469...    0.004158  \n",
       "2  [0.471439794621, 0.471389868978, 0.48552065950...    0.005240  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEAN_SCORES</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>SCORES</th>\n",
       "      <th>STD_SCORES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.514625</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[0.513047708223, 0.50890900552, 0.517944604815...</td>\n",
       "      <td>0.003467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.501321</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>[0.497336722115, 0.498439652359, 0.49720207704...</td>\n",
       "      <td>0.005166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470794</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>[0.462157473731, 0.467792671585, 0.48257941258...</td>\n",
       "      <td>0.007669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440248</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>[0.437373002227, 0.433996509004, 0.44772590159...</td>\n",
       "      <td>0.005180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.461471</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>[0.464829925804, 0.454389031791, 0.46416511469...</td>\n",
       "      <td>0.004158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.476431</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[0.471439794621, 0.471389868978, 0.48552065950...</td>\n",
       "      <td>0.005240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MEAN_SCORES                   MODEL  \\\n",
       "0     0.514625      LogisticRegression   \n",
       "1     0.501321               LinearSVC   \n",
       "2     0.470794           MultinomialNB   \n",
       "3     0.440248    KNeighborsClassifier   \n",
       "4     0.461471  DecisionTreeClassifier   \n",
       "5     0.476431  RandomForestClassifier   \n",
       "\n",
       "                                              SCORES  STD_SCORES  \n",
       "0  [0.513047708223, 0.50890900552, 0.517944604815...    0.003467  \n",
       "1  [0.497336722115, 0.498439652359, 0.49720207704...    0.005166  \n",
       "2  [0.462157473731, 0.467792671585, 0.48257941258...    0.007669  \n",
       "3  [0.437373002227, 0.433996509004, 0.44772590159...    0.005180  \n",
       "4  [0.464829925804, 0.454389031791, 0.46416511469...    0.004158  \n",
       "5  [0.471439794621, 0.471389868978, 0.48552065950...    0.005240  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.concat([df_result1, df_result2], ignore_index=True)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCORE_fold1</th>\n",
       "      <th>SCORE_fold2</th>\n",
       "      <th>SCORE_fold3</th>\n",
       "      <th>SCORE_fold4</th>\n",
       "      <th>SCORE_fold5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.513048</td>\n",
       "      <td>0.508909</td>\n",
       "      <td>0.517945</td>\n",
       "      <td>0.518345</td>\n",
       "      <td>0.514878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.497337</td>\n",
       "      <td>0.498440</td>\n",
       "      <td>0.497202</td>\n",
       "      <td>0.510813</td>\n",
       "      <td>0.502811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.462157</td>\n",
       "      <td>0.467793</td>\n",
       "      <td>0.482579</td>\n",
       "      <td>0.476700</td>\n",
       "      <td>0.464738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.437373</td>\n",
       "      <td>0.433997</td>\n",
       "      <td>0.447726</td>\n",
       "      <td>0.444914</td>\n",
       "      <td>0.437228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.464830</td>\n",
       "      <td>0.454389</td>\n",
       "      <td>0.464165</td>\n",
       "      <td>0.464917</td>\n",
       "      <td>0.459051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.471440</td>\n",
       "      <td>0.471390</td>\n",
       "      <td>0.485521</td>\n",
       "      <td>0.478302</td>\n",
       "      <td>0.475501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SCORE_fold1  SCORE_fold2  SCORE_fold3  SCORE_fold4  SCORE_fold5\n",
       "0     0.513048     0.508909     0.517945     0.518345     0.514878\n",
       "1     0.497337     0.498440     0.497202     0.510813     0.502811\n",
       "2     0.462157     0.467793     0.482579     0.476700     0.464738\n",
       "3     0.437373     0.433997     0.447726     0.444914     0.437228\n",
       "4     0.464830     0.454389     0.464165     0.464917     0.459051\n",
       "5     0.471440     0.471390     0.485521     0.478302     0.475501"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a scores dataframe\n",
    "# separating the scores column into 5\n",
    "df_scores = df_result['SCORES'].apply(pd.Series)\n",
    "df_scores.columns=['SCORE_fold1', 'SCORE_fold2', 'SCORE_fold3', 'SCORE_fold4', 'SCORE_fold5']\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEAN_SCORES</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>SCORES</th>\n",
       "      <th>STD_SCORES</th>\n",
       "      <th>SCORE_fold1</th>\n",
       "      <th>SCORE_fold2</th>\n",
       "      <th>SCORE_fold3</th>\n",
       "      <th>SCORE_fold4</th>\n",
       "      <th>SCORE_fold5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.514625</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[0.513047708223, 0.50890900552, 0.517944604815...</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.513048</td>\n",
       "      <td>0.508909</td>\n",
       "      <td>0.517945</td>\n",
       "      <td>0.518345</td>\n",
       "      <td>0.514878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.501321</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>[0.497336722115, 0.498439652359, 0.49720207704...</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.497337</td>\n",
       "      <td>0.498440</td>\n",
       "      <td>0.497202</td>\n",
       "      <td>0.510813</td>\n",
       "      <td>0.502811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470794</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>[0.462157473731, 0.467792671585, 0.48257941258...</td>\n",
       "      <td>0.007669</td>\n",
       "      <td>0.462157</td>\n",
       "      <td>0.467793</td>\n",
       "      <td>0.482579</td>\n",
       "      <td>0.476700</td>\n",
       "      <td>0.464738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440248</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>[0.437373002227, 0.433996509004, 0.44772590159...</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>0.437373</td>\n",
       "      <td>0.433997</td>\n",
       "      <td>0.447726</td>\n",
       "      <td>0.444914</td>\n",
       "      <td>0.437228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.461471</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>[0.464829925804, 0.454389031791, 0.46416511469...</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.464830</td>\n",
       "      <td>0.454389</td>\n",
       "      <td>0.464165</td>\n",
       "      <td>0.464917</td>\n",
       "      <td>0.459051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.476431</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[0.471439794621, 0.471389868978, 0.48552065950...</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>0.471440</td>\n",
       "      <td>0.471390</td>\n",
       "      <td>0.485521</td>\n",
       "      <td>0.478302</td>\n",
       "      <td>0.475501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MEAN_SCORES                   MODEL  \\\n",
       "0     0.514625      LogisticRegression   \n",
       "1     0.501321               LinearSVC   \n",
       "2     0.470794           MultinomialNB   \n",
       "3     0.440248    KNeighborsClassifier   \n",
       "4     0.461471  DecisionTreeClassifier   \n",
       "5     0.476431  RandomForestClassifier   \n",
       "\n",
       "                                              SCORES  STD_SCORES  SCORE_fold1  \\\n",
       "0  [0.513047708223, 0.50890900552, 0.517944604815...    0.003467     0.513048   \n",
       "1  [0.497336722115, 0.498439652359, 0.49720207704...    0.005166     0.497337   \n",
       "2  [0.462157473731, 0.467792671585, 0.48257941258...    0.007669     0.462157   \n",
       "3  [0.437373002227, 0.433996509004, 0.44772590159...    0.005180     0.437373   \n",
       "4  [0.464829925804, 0.454389031791, 0.46416511469...    0.004158     0.464830   \n",
       "5  [0.471439794621, 0.471389868978, 0.48552065950...    0.005240     0.471440   \n",
       "\n",
       "   SCORE_fold2  SCORE_fold3  SCORE_fold4  SCORE_fold5  \n",
       "0     0.508909     0.517945     0.518345     0.514878  \n",
       "1     0.498440     0.497202     0.510813     0.502811  \n",
       "2     0.467793     0.482579     0.476700     0.464738  \n",
       "3     0.433997     0.447726     0.444914     0.437228  \n",
       "4     0.454389     0.464165     0.464917     0.459051  \n",
       "5     0.471390     0.485521     0.478302     0.475501  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate both dataframes\n",
    "df_result = pd.concat([df_result, df_scores], axis=1)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEAN_SCORES</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>STD_SCORES</th>\n",
       "      <th>SCORE_fold1</th>\n",
       "      <th>SCORE_fold2</th>\n",
       "      <th>SCORE_fold3</th>\n",
       "      <th>SCORE_fold4</th>\n",
       "      <th>SCORE_fold5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.514625</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.513048</td>\n",
       "      <td>0.508909</td>\n",
       "      <td>0.517945</td>\n",
       "      <td>0.518345</td>\n",
       "      <td>0.514878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.501321</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.497337</td>\n",
       "      <td>0.498440</td>\n",
       "      <td>0.497202</td>\n",
       "      <td>0.510813</td>\n",
       "      <td>0.502811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470794</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.007669</td>\n",
       "      <td>0.462157</td>\n",
       "      <td>0.467793</td>\n",
       "      <td>0.482579</td>\n",
       "      <td>0.476700</td>\n",
       "      <td>0.464738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440248</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>0.437373</td>\n",
       "      <td>0.433997</td>\n",
       "      <td>0.447726</td>\n",
       "      <td>0.444914</td>\n",
       "      <td>0.437228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.461471</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.464830</td>\n",
       "      <td>0.454389</td>\n",
       "      <td>0.464165</td>\n",
       "      <td>0.464917</td>\n",
       "      <td>0.459051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.476431</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>0.471440</td>\n",
       "      <td>0.471390</td>\n",
       "      <td>0.485521</td>\n",
       "      <td>0.478302</td>\n",
       "      <td>0.475501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MEAN_SCORES                   MODEL  STD_SCORES  SCORE_fold1  SCORE_fold2  \\\n",
       "0     0.514625      LogisticRegression    0.003467     0.513048     0.508909   \n",
       "1     0.501321               LinearSVC    0.005166     0.497337     0.498440   \n",
       "2     0.470794           MultinomialNB    0.007669     0.462157     0.467793   \n",
       "3     0.440248    KNeighborsClassifier    0.005180     0.437373     0.433997   \n",
       "4     0.461471  DecisionTreeClassifier    0.004158     0.464830     0.454389   \n",
       "5     0.476431  RandomForestClassifier    0.005240     0.471440     0.471390   \n",
       "\n",
       "   SCORE_fold3  SCORE_fold4  SCORE_fold5  \n",
       "0     0.517945     0.518345     0.514878  \n",
       "1     0.497202     0.510813     0.502811  \n",
       "2     0.482579     0.476700     0.464738  \n",
       "3     0.447726     0.444914     0.437228  \n",
       "4     0.464165     0.464917     0.459051  \n",
       "5     0.485521     0.478302     0.475501  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the original 'SCORES' column\n",
    "df_result.drop('SCORES', axis=1, inplace=True)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>SCORE_fold1</th>\n",
       "      <th>SCORE_fold2</th>\n",
       "      <th>SCORE_fold3</th>\n",
       "      <th>SCORE_fold4</th>\n",
       "      <th>SCORE_fold5</th>\n",
       "      <th>MEAN_SCORES</th>\n",
       "      <th>STD_SCORES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.513048</td>\n",
       "      <td>0.508909</td>\n",
       "      <td>0.517945</td>\n",
       "      <td>0.518345</td>\n",
       "      <td>0.514878</td>\n",
       "      <td>0.514625</td>\n",
       "      <td>0.003467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.497337</td>\n",
       "      <td>0.498440</td>\n",
       "      <td>0.497202</td>\n",
       "      <td>0.510813</td>\n",
       "      <td>0.502811</td>\n",
       "      <td>0.501321</td>\n",
       "      <td>0.005166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.462157</td>\n",
       "      <td>0.467793</td>\n",
       "      <td>0.482579</td>\n",
       "      <td>0.476700</td>\n",
       "      <td>0.464738</td>\n",
       "      <td>0.470794</td>\n",
       "      <td>0.007669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.437373</td>\n",
       "      <td>0.433997</td>\n",
       "      <td>0.447726</td>\n",
       "      <td>0.444914</td>\n",
       "      <td>0.437228</td>\n",
       "      <td>0.440248</td>\n",
       "      <td>0.005180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.464830</td>\n",
       "      <td>0.454389</td>\n",
       "      <td>0.464165</td>\n",
       "      <td>0.464917</td>\n",
       "      <td>0.459051</td>\n",
       "      <td>0.461471</td>\n",
       "      <td>0.004158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.471440</td>\n",
       "      <td>0.471390</td>\n",
       "      <td>0.485521</td>\n",
       "      <td>0.478302</td>\n",
       "      <td>0.475501</td>\n",
       "      <td>0.476431</td>\n",
       "      <td>0.005240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    MODEL  SCORE_fold1  SCORE_fold2  SCORE_fold3  SCORE_fold4  \\\n",
       "0      LogisticRegression     0.513048     0.508909     0.517945     0.518345   \n",
       "1               LinearSVC     0.497337     0.498440     0.497202     0.510813   \n",
       "2           MultinomialNB     0.462157     0.467793     0.482579     0.476700   \n",
       "3    KNeighborsClassifier     0.437373     0.433997     0.447726     0.444914   \n",
       "4  DecisionTreeClassifier     0.464830     0.454389     0.464165     0.464917   \n",
       "5  RandomForestClassifier     0.471440     0.471390     0.485521     0.478302   \n",
       "\n",
       "   SCORE_fold5  MEAN_SCORES  STD_SCORES  \n",
       "0     0.514878     0.514625    0.003467  \n",
       "1     0.502811     0.501321    0.005166  \n",
       "2     0.464738     0.470794    0.007669  \n",
       "3     0.437228     0.440248    0.005180  \n",
       "4     0.459051     0.461471    0.004158  \n",
       "5     0.475501     0.476431    0.005240  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting the final dataset\n",
    "df_result = df_result[['MODEL', 'SCORE_fold1', 'SCORE_fold2', 'SCORE_fold3',\n",
    "                       'SCORE_fold4', 'SCORE_fold5','MEAN_SCORES', 'STD_SCORES']]\n",
    "\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Improve chosen models\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Build a machine learning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models that we'll use in the final pipeline\n",
    "lr_clf = LogisticRegression(random_state = random_state)\n",
    "svc_clf = LinearSVC(random_state = random_state)\n",
    "rf_clf = RandomForestClassifier(random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # code doesn't run due to workspace expiration\n",
    "\n",
    "# # few model tunning with pipelinehelper\n",
    "\n",
    "# def model_pipeline():\n",
    "#     pipeline = Pipeline([\n",
    "#         ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "#         ('tfidf', TfidfTransformer()),\n",
    "#         ('classifier', PipelineHelper([\n",
    "#             ('lr', MultiOutputClassifier(lr_clf)),\n",
    "#             ('svc', MultiOutputClassifier(svc_clf)),\n",
    "#             ('rf', MultiOutputClassifier(rf_clf))\n",
    "#     ]))\n",
    "# ])\n",
    "\n",
    "#     return pipeline\n",
    "\n",
    "# pipeline = model_pipeline()\n",
    "\n",
    "\n",
    "# params = {\n",
    "#     'vect__decode_error' : ['strict', 'ignore', 'replace'],\n",
    "#     'tfidf__norm' : ['l1', 'l2'],\n",
    "#     'classifier__selected_model': pipeline.named_steps['classifier'].generate({\n",
    "#         'lr__estimator__penalty' : ['l1', 'l2'],\n",
    "#         'lr__estimator__C' : [1, 10],\n",
    "#         'svc__estimator__loss': ['hinge', 'squared_hinge'],\n",
    "#         'svc__estimator__C' : [1, 10],\n",
    "#         'svc__estimator__multi_class': ['ovr', 'crammer_singer'],\n",
    "#         'rf__estimator__n_estimators': [10, 100],\n",
    "#         'rf__estimator__min_samples_leaf' : [1, 3]       \n",
    "#     })\n",
    "# }\n",
    "\n",
    "# cv = GridSearchCV(pipeline, param_grid = params, n_jobs=-1)\n",
    "# cv.fit(X_train, y_train)\n",
    "# cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(model):\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('classifier', MultiOutputClassifier(model))   \n",
    "])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "pipeline1 = model_pipeline(lr_clf)\n",
    "pipeline2 = model_pipeline(svc_clf)\n",
    "pipeline3 = model_pipeline(rf_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = {\n",
    "    'vect__decode_error' : ['strict', 'ignore', 'replace'],\n",
    "    'tfidf__norm' : ['l1', 'l2'],\n",
    "    'classifier__estimator__penalty' : ['l1', 'l2'],\n",
    "    'classifier__estimator__C' : [0.1, 1, 5, 10],\n",
    "    'classifier__estimator__max_iter' : [500, 1000, 5000]\n",
    "}\n",
    "\n",
    "\n",
    "params2 = {\n",
    "    'vect__decode_error' : ['strict', 'ignore', 'replace'],\n",
    "    'tfidf__norm' : ['l1', 'l2'],\n",
    "    'classifier__estimator__loss' : ['hinge', 'squared_hinge'],\n",
    "    'classifier__estimator__C' : [1, 10],\n",
    "    'classifier__estimator__multi_class': ['ovr', 'crammer_singer']\n",
    "}\n",
    "\n",
    "\n",
    "params3 = {\n",
    "    'vect__decode_error' : ['strict', 'ignore', 'replace'],\n",
    "    'tfidf__norm' : ['l1', 'l2'],        \n",
    "    'classifier__estimator__n_estimators': [10, 100],\n",
    "    'classifier__estimator__min_samples_leaf' : [1, 3]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = GridSearchCV(pipeline1, params1, n_jobs=-1)\n",
    "cv1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2 = GridSearchCV(pipeline2, params2, n_jobs=-1)\n",
    "# cv2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv3 = GridSearchCV(pipeline3, params3, n_jobs=-1)\n",
    "# cv3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__estimator__C': 1,\n",
       " 'classifier__estimator__penalty': 'l1',\n",
       " 'tfidf__norm': 'l2',\n",
       " 'vect__decode_error': 'strict'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__estimator__C': 1,\n",
       " 'classifier__estimator__loss': 'hinge',\n",
       " 'classifier__estimator__multi_class': 'ovr',\n",
       " 'tfidf__norm': 'l2',\n",
       " 'vect__decode_error': 'strict'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__estimator__min_samples_leaf': 1,\n",
       " 'classifier__estimator__n_estimators': 100,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'vect__decode_error': 'strict'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv3.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.85      0.94      0.89      3983\n",
      "               request       0.82      0.55      0.66       931\n",
      "                 offer       0.00      0.00      0.00        20\n",
      "           aid_related       0.79      0.65      0.72      2226\n",
      "          medical_help       0.66      0.21      0.31       447\n",
      "      medical_products       0.65      0.26      0.37       284\n",
      "     search_and_rescue       0.71      0.15      0.24       170\n",
      "              security       0.33      0.02      0.04       104\n",
      "              military       0.64      0.23      0.34       189\n",
      "                 water       0.81      0.58      0.67       371\n",
      "                  food       0.82      0.69      0.75       597\n",
      "               shelter       0.78      0.57      0.66       477\n",
      "              clothing       0.76      0.40      0.53        77\n",
      "                 money       0.57      0.21      0.30       112\n",
      "        missing_people       0.75      0.13      0.23        68\n",
      "              refugees       0.69      0.22      0.33       167\n",
      "                 death       0.76      0.44      0.55       245\n",
      "             other_aid       0.58      0.13      0.22       715\n",
      "infrastructure_related       0.49      0.06      0.11       343\n",
      "             transport       0.56      0.15      0.23       247\n",
      "             buildings       0.67      0.33      0.45       258\n",
      "           electricity       0.56      0.21      0.31       103\n",
      "                 tools       0.00      0.00      0.00        36\n",
      "             hospitals       0.40      0.04      0.06        57\n",
      "                 shops       0.00      0.00      0.00        18\n",
      "           aid_centers       0.20      0.01      0.03        67\n",
      "  other_infrastructure       0.52      0.05      0.09       229\n",
      "       weather_related       0.87      0.70      0.77      1489\n",
      "                floods       0.91      0.51      0.65       434\n",
      "                 storm       0.76      0.57      0.65       505\n",
      "                  fire       0.56      0.18      0.27        56\n",
      "            earthquake       0.89      0.76      0.82       509\n",
      "                  cold       0.71      0.25      0.37       107\n",
      "         other_weather       0.56      0.12      0.19       277\n",
      "         direct_report       0.76      0.45      0.57      1029\n",
      "\n",
      "           avg / total       0.77      0.58      0.63     16947\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = cv1.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=Y.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cv1, open('message_lr_classifier.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
